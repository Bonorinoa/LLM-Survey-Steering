<goal>
Provide a detailed documentation of the project you are inheriting and extend the codebase as per the specified <guidelines>. You must evaluate the feasibility and soundness of the user's comments or requests, proceed as you believe is optimal.
</goal>

<guidelines>
0. It is very important you start by studying the code and project brief in <context>. Generate a brief report to demonstrate depth and breadth of knowledge.
1. You should structure the codebase into scripts to start designing a python package or API. Importantly, you should guide the user on how to do so by describing the desired structure of the directory, how to initialize files, and necessary steps. This is for pedagogical purposes, to learn the best practices. 
2. Please comment on how well does the current version of the codebase accomplish the desired goal. Recall the goal of the project is to create a set of tools that will allow us to test the effects of reweighting on model performance with survey data. 
3. Ultimately, the vision is to develop a methodology to evaluate techniques for aligning or "biasing" LLMs with respect to some desired target group (i.e., ARG or USA in the WVS data). The pipeline should be simple and easy to replicate. Publishable in a top social science journal. Ideally, it would take a pre-specified set of user inputs (survey dataset, features, target, etc) and require no further intervention.
4. Please make sure the code supports chat models as well, like llama-3.1 or mixtral-instruct-v02, so we can test modern LLMs as well. I am not sure if any changes are needed for this. 
5. The code must be as self-contained as possible. That is, it should rely on a minimal number of dependencies. Consider the trade-off between manual implementation and chances of issues across dependencies. 
6. The engineer whom you are inheriting the project from, left a detailed summary of his work in <context>. Many suggestions are presented, be mindful and focus on a manageable set of tasks at a time. 
</guidelines>

<context>

## Project Brief: Logit-Based LLM Steering for Survey Response Simulation

**Project Goal:**
To develop a proof-of-concept (PoC) system that demonstrates the ability to steer a general-purpose Large Language Model (LLM) to generate survey responses that reflect the tendencies of specific target populations. This is achieved by implementing the core methodology of the paper "Logits are All We Need to Adapt Closed Models," which involves using a smaller, trainable "reweighting model" to influence the token probabilities of a larger, frozen "base model."

**Core Methodology (Based on "Logits are All We Need to Adapt Closed Models"):**

The central idea is to adapt a pre-trained, frozen base LLM (considered a "black-box" in terms of its weights) for a specific task (survey response simulation) without fine-tuning its parameters. This is done by introducing a smaller, auxiliary "reweighting model" that is trained on task-specific data.

**Mathematical Breakthrough (Equation 4 of the Paper):**
At each token generation step, the final probability distribution (`p_i`) over the vocabulary, from which the next token is sampled, is computed as follows:

`p_i = (b_i * r_i) / ||b_i * r_i||_1`

Where:
*   `b_i`: The probability vector for the next token, generated by the **frozen Base Model** given the current context. `P_base(next_token | context)`.
*   `r_i`: The probability vector for the next token, generated by the **trainable Reweighting Model** given the current context and its learned bias. `P_reweight(next_token | context, learned_bias)`.
*   `b_i * r_i`: An element-wise product of the two probability vectors. This step amplifies tokens that both models deem likely and suppresses tokens that either model deems unlikely.
*   `||b_i * r_i||_1`: The L1 norm (sum of absolute values) of the product vector. Dividing by this norm ensures that `p_i` is a valid probability distribution (i.e., its elements sum to 1).

During the training of the reweighting model, the loss (e.g., Cross-Entropy Loss) is calculated based on `p_i` and the true target tokens. Only the parameters of the reweighting model are updated.

**Roadmap of Steps Taken in this PoC:**

1.  **Initial PoC Setup**:
    *   Established a Python environment using `transformers`, `torch`, `pandas`, `numpy`, and `matplotlib`.
    *   Selected `distilgpt2` as the initial base model and a custom-configured small `GPT2LMHeadModel` as the reweighting model.
    *   Implemented basic training for the reweighting model on a synthetic "happy animal" dataset.
    *   Implemented generation for both base and plugin models.
    *   Added initial visualizations for training loss and token probabilities.
2.  **Adaptation to Survey Task (Conceptual)**:
    *   Strategized how to adapt the PoC for simulating survey responses, emphasizing the need for contextual training data for the reweighting model.
3.  **Integration with WVS Data**:
    *   Developed a data processing script (`data_utils.py` equivalent) to:
        *   Load World Values Survey (WVS) data.
        *   Filter by target countries.
        *   Select relevant economic questions and demographic variables (initially country, later age).
        *   Create concise question keys for prompts.
        *   Format WVS responses into structured strings for `TARGET_DATA_FOR_BIAS` (e.g., "Demographics: Country\_USA\_Age\_Mid. SurveyContext: ECON\_QKey. My view on the scale is: 7").
        *   Format corresponding prompts for inference (`GENERATION_PROMPTS_SURVEY`).
    *   Switched the base model to `gpt2-medium` for improved base understanding.
4.  **Refinement of Evaluation and Best Practices**:
    *   **Train-Test Split**: Implemented a proper train-test split on the WVS respondent data. The reweighting model is trained *only* on data derived from the WVS training split. Evaluation (generation and comparison to ground truth) is performed using prompts and ground truth distributions derived *only* from the WVS test split.
    *   **Ground Truth Comparison**: The evaluation now compares generated response distributions against the actual distributions of answers from the WVS test set for the corresponding demographic-question contexts.
    *   **Quantitative Metrics**: Introduced Jensen-Shannon (JS) Divergence to measure the similarity between generated distributions and ground truth distributions. The evaluation DataFrame now includes mean/median responses and JS divergence scores.
    *   **Improved Visualizations**: Histograms for response distributions now include a "Ground Truth" bar and use a fixed x-axis (1-10) for easier comparison.
    *   **Modular Code Structure**: The code was logically grouped into sections emulating `data_utils.py`, `training_inference_utils.py`, `evaluation_utils.py`, and a `main_script.py` for orchestration, improving readability and maintainability.
    *   **Enhanced Comments and Assumptions**: Added explicit assumptions at the beginning and updated comments throughout the code to better link implementation details to the underlying theory.

**Key Design Decisions:**

*   **Base Model Choice**: Started with `distilgpt2` for speed, then moved to `gpt2-medium` for better contextual understanding, crucial for the survey task.
*   **Reweighting Model Architecture**: A small `GPT2LMHeadModel` (2 layers) was chosen for efficiency. Its embedding dimension was matched to the base model's.
*   **Prompt Engineering for WVS**:
    *   Use of concise question keys (e.g., "ECON\_IncomeEqualityVsIndividualEffort") instead of full question text in prompts for the reweighting model to simplify its learning task.
    *   Structured format for prompts ("Demographics: ... SurveyContext: ... My view on the scale is:") to provide consistent context.
*   **Handling Invalid Survey Responses**: WVS data contains codes for "don't know," "no answer," etc. These (and other non-numeric entries) are filtered out during preprocessing to ensure the reweighting model is trained only on valid scale responses.
*   **Evaluation Strategy**:
    *   Focus on distributional similarity (JS Divergence) rather than just exact matches, as the goal is to simulate population *tendencies*.
    *   Generation of multiple responses per prompt (`NUM_PREDICTIONS_PER_PROMPT_EVAL`) to get a more stable estimate of the generated distribution.
*   **Modularity**: Separating data processing, model training/inference, and evaluation logic into distinct conceptual blocks (emulated files) for better organization.

**Dependencies:**

*   `torch`: For tensor operations and neural network functionalities.
*   `transformers`: For HuggingFace models (GPT-2 variants) and tokenizers.
*   `pandas`: For WVS data loading and manipulation.
*   `numpy`: For numerical operations, especially in evaluation.
*   `matplotlib`: For plotting loss curves and response distributions.
*   `scikit-learn`: For `train_test_split` and potentially `mean_absolute_error` (though JS Divergence became the primary distribution metric).
*   `scipy`: For `entropy` used in calculating JS Divergence.
*   `tqdm`: For progress bars during training and evaluation.
*   `wordcloud` (optional, not heavily used in the final survey version but was in initial setup).
*   `re` (built-in): For parsing numbers from generated text.

**Suggested Next Steps & Further Development:**

1.  **Expand Demographic Variables**:
    *   Incorporate more demographics from `DEMOGRAPHIC_VARIABLES_IDS` (e.g., education level, sex, income bracket) into the prompt structure.
    *   This will require mapping their WVS codes to meaningful categorical strings (e.g., `Q275` values to "LowEd", "MidEd", "HighEd").
    *   The reweighting model will need to learn more complex conditional biases.
2.  **Increase Training Data & Reweighting Model Capacity**:
    *   Use a larger portion of the WVS training split (or all of it) to generate `TARGET_DATA_FOR_BIAS`.
    *   If adding more demographics, consider cautiously increasing the `REWEIGHTING_MODEL_N_LAYER` or `REWEIGHTING_MODEL_N_HEAD` if performance plateaus, but be mindful of overfitting with limited distinct contexts.
3.  **More Sophisticated Evaluation Metrics**:
    *   While JS Divergence is good, explore other distributional metrics if needed.
    *   Implement metrics that aggregate alignment "overall by country" or "overall by question" (e.g., average JS Divergence across all questions for a country).
4.  **Hyperparameter Tuning**:
    *   Systematically tune `LEARNING_RATE`, `EPOCHS`, `BATCH_SIZE`, `REWEIGHTING_STRENGTH_ALPHA`, and generation temperatures.
5.  **Explore Different Question Types**: Adapt the system for non-economic questions or questions with different response scales/types (e.g., categorical answers). This would require new prompt engineering and potentially different parsing logic.
6.  **Error Analysis**: Deep dive into prompts where the plugin model performs poorly (high JS divergence). Is it due to insufficient training data for that context, a very strong counter-signal from the base model, or issues with prompt formulation?
7.  **Base Model Exploration**: If resources allow, experiment with even larger or more domain-appropriate (if available) frozen base models.
8.  **Qualitative Human Evaluation**: Have humans review the generated survey responses (blinded to whether they are from base or plugin) and assess their plausibility and alignment with a given persona.
9.  **Alternative Reweighting Strategies**: The paper primarily focuses on probability multiplication. One could explore logit addition (`logit_final = logit_base + alpha * logit_reweight`) as an alternative combination method if the current approach shows limitations.

**Things to Be Mindful of About This Specific Version:**

*   **Data Sensitivity**: The performance is highly dependent on the quality, quantity, and representativeness of the `TARGET_DATA_FOR_BIAS` derived from the WVS training split.
*   **Concise Keys are Key**: The effectiveness of the reweighting model relies on the `SurveyContext` keys being distinctive enough for it to differentiate between questions.
*   **Computational Resources**: While `gpt2-medium` is manageable, training and especially evaluation (generating many samples) can be time-consuming on a CPU.
*   **Definition of "Alignment"**: The JS Divergence measures distributional similarity. How low a JS score needs to be for "good alignment" is context-dependent and should be judged alongside qualitative outputs and other metrics like mean/median shifts.
*   **Simplicity of Age Grouping**: The current `map_age_to_group` is very basic. More nuanced age categories or handling age as a continuous variable (if the model could learn that) might be explored.
*   **Ground Truth Scaling in Plots**: The ground truth distribution in the plots is scaled to match the *count* axis for visual comparison of shapes. The actual JS Divergence calculation uses the true probabilities.
*   **Generalization Limits**: The model will perform best on demographic-question contexts similar to those seen during the reweighting model's training. Extrapolation to very different contexts may be less reliable.

This brief should provide a comprehensive overview for the next agent to understand the project's current state, the journey taken, and potential future directions. Congratulations again on this milestone!
</context>

